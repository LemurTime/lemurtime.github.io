[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/haiku-20251029/index.html",
    "href": "posts/haiku-20251029/index.html",
    "title": "Writing Haiku with GPT-2 Without Finetuning",
    "section": "",
    "text": "The early days of LLMs\nSix years ago, ChatGPT didn‚Äôt exist, and LLMs weren‚Äôt reasoning or doing people‚Äôs homework, but they were thrilling all the same. My machine learning journey started in 2018 - I was in South Sudan and trying to use AI to count cows from space. By late 2019, I was living in Madagascar, and bought a Jetson Nano to run ML models without depending on an internet connection. As a literature PhD, I wanted to see how well the LLM could generate creative work, and the haiku seemed like a good test case.\nAround that time, some excellent GPT-2 haiku projects (such as https://github.com/brianweet/gpt-2-haiku) used fine-tuning to generate interesting results. The Jetson Nano didn‚Äôt have enough memory to fine-tune the model, so I experimented with the base model using inference alone.\nI wrote code which prompted GPT-2 with a haiku-themed seed and then pieced together output of the right syllable count. Each poem took about one minute to generate, appearing upon a small external monitor until the next one was finished - an ephemeral dance accompanied by the furious spinning of the fan. The results were mostly absurd, but occasionally interesting.\n\n\n\nIMG_2688.JPG\n\n\nRecently, I wondered if a modern LLM assistant could write code to get better results from GPT-2.\nGPT-2 now runs easily on a laptop. The examples below show the sort of output the model would produce without finetuning, quickly becoming incoherent. (I remember an early chatbot experiment that seemed to work fine until my spouse tested it. In an example of early AI safety red-teaming, she got it to generate an endless string of ‚ÄúDIE DIE DIE DIE DIE‚Äù within 5 turns.)\n\nimport transformers\n\nThis is what happens with prompts like ‚ÄúHaiku‚Äù or ‚ÄúHere is a Haiku:‚Äù\n\nfrom transformers import pipeline, set_seed\ngenerator = pipeline('text-generation', model='gpt2')\nset_seed(42)\n\n\ngenerator(\"Here is a haiku poem,\", num_return_sequences=5)\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\n[{'generated_text': 'Here is a haiku poem, written by an American writer, in which he describes the story of the first American man to commit suicide in the world.\\n\\nThe poem is called \"The Way of the Soldier.\"\\n\\nThe story about the first man to commit suicide in the world\\n\\nWritten by: Charles P. Smith, Jr.\\n\\nEdited by: Robert L. Williams\\n\\nThe poem was published in 1858 as a short story.\\n\\nThe poem was written about a man named \"Vincent\" who committed suicide, after which he read his own poem and asked for forgiveness from his fellow citizens.\\n\\nIn 1859, Vincent wrote, \"I am a man of spirit, a man of courage. A man of courage. A man of spirit. A man of courage. A man of courage.\"\\n\\nVincent continued, \"I am not afraid of anything, of the world, of life. I am not afraid of any thing, of my fellow men, of the world, of death. I am not afraid of the world. I am not afraid of anything, of the world, of life. I am not afraid of any thing, of the world, of death. I am not afraid of any thing, of my fellow men, of the world'},\n {'generated_text': 'Here is a haiku poem, \"To die for my name\" by Nils Nils.\\n\\nThis is the original poem by Nils Nils.\\n\\nThe first part was composed for the novel \"The Long Night\".\\n\\nThe second part was composed for the novel \"The Long Night\" by Nils Nils.\\n\\nThe third part was composed for the novel \"The Long Night\" by Nils Nils.\\n\\nThe fourth part was composed for the novel \"The Long Night\" by Nils Nils.\\n\\nThe fifth part was composed for the novel \"The Long Night\" by Nils Nils.\\n\\nThe sixth part was composed for the novel \"The Long Night\" by Nils Nils.\\n\\nThe seventh part was composed for the novel \"The Long Night\" by Nils Nils.\\n\\n\\nThe eighth part was composed for the novel \"The Long Night\" by Nils Nils.\\n\\n\\nThe ninth part was composed for the novel \"The Long Night\" by Nils Nils.\\n\\n\\nThe tenth part was composed for the novel \"The Long Night\" by Nils Nils.\\n\\n\\nThe eleventh part was composed for the novel \"The Long Night\" by Nils Nils.\\n\\nThe tw'},\n {'generated_text': 'Here is a haiku poem, adapted from a poem about a young boy:\\n\\nI am the son of an old man,\\n\\nand the father of a young girl.\\n\\nAnd the day of the coming of the sun,\\n\\nthe year, the year,\\n\\nthe year of heaven.\\n\\nI am the son of an old man, and the father of a young girl.\\n\\nBut when the sun comes, the year, the year of heaven,\\n\\nthe year of the moon,\\n\\nthe year of the stars,\\n\\nand the year of the angels;\\n\\nI am the son of an old man, and the father of a young girl.\\n\\nBut when the sun comes, the year, the year of heaven,\\n\\nthe year of the moon,\\n\\nthe year of the stars,\\n\\nand the year of the angels;\\n\\nI am the son of an old man, and the father of a young girl.\\n\\nBut when the sun comes, the year, the year of heaven,\\n\\nthe year of the moon,\\n\\nthe year of the stars,\\n\\nand the year of the angels;\\n\\nI am the son of an old man, and the father of a young girl.'},\n {'generated_text': \"Here is a haiku poem, which I found on my way to work.\\n\\nI read it for the first time in my head when I was a kid and it's a pretty short poem about a boy who loves to eat. It's a good story about a boy who's lost his love and ends up as a child.\\n\\nThere is a scene where a young girl comes to the end of the story, and she's crying and she says the word 'love' and what am I doing to my mom and dad and what about my dad. And the girl says, 'I love you too and I am your best friend, oh my god, I love you too!' And she goes, 'I love you, my mommy loves you too. I love you too, my mommy loves you too.' I think that's a good bit of emotional empathy, if you will.\\n\\nIt's a pretty short story. On my back are a few words that I've said often enough, but I think the gist is this:\\n\\nI love you, my mommy loves you too. I love you, my mommy loves you too. I love you, my mommy loves you too. I love you, my mommy loves you too.\\n\\nThere\"},\n {'generated_text': 'Here is a haiku poem, from a popular Japanese language book, published in the early 1950s, by the famous Japanese singer Takayuki Utsukai.\\n\\n\\nThe poem was sung at the University of California, Berkeley in 1952. It was featured in a film called \"The Love Song of the Spring\".\\n\\n\\nThe film\\'s star was Takayuki Utsukai. In the film, Utsukai was portrayed by a young Japanese man named Akiyobu Suzuki, and the film\\'s director was the Japanese novelist Yoshinori Kitano.\\n\\n\\nUtsukai\\'s name was also mentioned as a character in \"Love Song of the Spring\".\\n\\n\\nThe poem was translated into English by the English version of the popular Japanese manga series \"One Piece\". The novel\\'s title refers to the title character, Utsukai.\\n\\n\\nThe poem was also adapted into the novel by the singer-songwriter Otsuki Yoshinori.\\n\\n\\nIn the novel, this haiku poem was read aloud and translated into Japanese.\\n\\n\\nUtsukai was also an idol in the idol group the Kinkaku Yakuza.\\n\\n\\nIn addition to a song, there were also other haikus included in the anime.\\n\\n\\nThere were'}]\n\n\n\ngenerator(\"HAIKU:\", num_return_sequences=5)\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\n[{'generated_text': 'HAIKU: Right. I want to tell you, I\\'m not going to go into detail about what he does there, but he\\'s a big fan of a lot of the things you can relate to in terms of the things he\\'s doing here. He\\'s just a really great guy. He\\'s really into the game. He has a lot of love for the game and wants to try to make it better. I could go on and on. But I\\'m going to leave it there.\\n\\nQ: If there\\'s anything you would like to add in the future, what would it be?\\n\\nA: I\\'m sure we\\'ll get to that. I\\'m sure you\\'ll have to wait and see.\\n\\nQ: I know you said you were going to do the \"No-Sell List\" thing. Are you still looking for a new GM?\\n\\nA: I\\'m definitely looking to do it. I\\'m sure I\\'ve done it before. I\\'m not looking to do that. I\\'m just looking to hire somebody who can bring that expertise to the table.\\n\\nQ: Do you have any specific plans for next season?\\n\\nA: We\\'ve got a lot of work ahead of us on that. I\\'m excited for what'},\n {'generated_text': 'HAIKU: You saw that? (laughs) I think he was making a lot of money. It was like, \"Oh my God, that\\'s going to be a lot bigger than what I paid for.\"\\n\\nMARK: It was. (laughs)\\n\\nKATIE: It was. You got to see it. I got to see it.\\n\\nMARK: So, I mean, I mean, that\\'s what a lot of us do. We were all working on the film and we got to see it.\\n\\nKATIE: Yeah, yeah.\\n\\nMARK: How about when you\\'re working on a film, how do you get to see it and what do you get to see?\\n\\nKATIE: Well, I get to see it when I\\'m working on a film. And I get to see it when I\\'m working on a film.\\n\\nMARK: Oh, you\\'re right.\\n\\nKATIE: The last time I saw it, it was a little bit darker than it was in the first place.\\n\\nMARK: (laughs)\\n\\nKATIE: I mean, it\\'s a little bit darker. And when I was making that movie, I was feeling'},\n {'generated_text': 'HAIKU: The Unfair Test Demon, Aamir Demon God Dragon, Baal awoken sinner Demon King, Zaerog‚àû Demon Lord, Belial Demon King, Cauchemar Demon Man, Metatron Demon Messenger, Metatron TAMADRA Fallen Angel Lucifer Fastest Sky Pirate, Balthier Demon Lord, Belial Demon Lord, Buster Siegfried Demon Lord, Buster Siegfried Protector of the Sea, Ganesha Demon God, Ra Dragon Anubis Demon God of Fury, Ares demon of the damned, beelzebub Demon God of the Climactic Night, Lucifer Demon God of the Night, Tsukuyomi Dragon Anubis Demon God of Steel, Verra Demon which Kill Devil Dragon, Canopus Ateria Demon Weal, Shouki Demon Blade Brave, Kopisubi The Flash Maleficent Dragon Lord Zaerog‚àû Demon Lord, Furi Zoldyck Thunderdragon Indra Thundering CyberDragon, Shedar Thunderlord Shocker Thunderlord Zinogre Thunderous Demon Princess, Raijin Thunderous Screaming Demon Count, Ronove Thundershock Tiger Dragon, Balidoora Thunderstone Edge, Caladbolg Tiamat Tidus Tifa Tigrex Tigrex & Rex Cat Timbel Armor X Dragon Caller, Ana Time Guardians, Tak'},\n {'generated_text': \"HAIKU: The Demon's Trap The Game The Challenge The Chaos Engine The Charming Empire The Charnel House Trilogy The Chosen RPG The Chosen Warriors The chronicles of Emerland. Solitaire. The Clans - Saga of the Twins The Cleansing The Collider The Collider 2 The Coma The Coma: Recut The Concourse The Confines Of The Crown The Construct The Consuming Shadow The Cooking Game The Corridor: On Behalf Of The Dead The Council The Count Lucanor The Counting Kingdom The Crooked Man The Crow's Eye The Crowded Party Game Collection The Crypts of Anak Shaba - VR The Culling Of The Cows The Curious Expedition The Cursed Forest The Dark Eye: Chains of Satinav The Dark Inside Me The Dark Legions The Dark Stone from Mebara The Dark Tales of Katarina The Darkside Detective The Dead Linger The Deadly Tower of Monsters The Deal The Decimation of Olarath The Deed The Deed: Dynasty The Deer The Deer God The Defenders: The Second Wave The Deletion The Descendant The Detail The Dishwasher: Vampire Smile The Disney Afternoon Collection The District The Divine Paradox The Dolls The Dope Game The Dream Machine The Dreamatorium of Dr. Magnus 2 The Dreamlord The\"},\n {'generated_text': \"HAIKU: That's the kind of story I always wanted to hear. I have a family that I don't really know well, but I've had some good conversations with other families. I'm a professional hockey player, and I'm a professional broadcaster, and I've seen a lot of great things in the past, but I'm not sure yet how I would want to continue playing hockey in my life.\\n\\nA: When we were talking about the future, you were talking about a certain player, but it was also about you and the guys, and the team, and the fans, and the fans‚Äîyou were doing a great job.\\n\\nAdvertisement\\n\\nQ: And you're not going to play for the team again?\\n\\nA: No, I'm not going to play for the team in any way.\\n\\nQ: You're not going to play for the team, but you're going to play for a certain team?\\n\\nAdvertisement\\n\\nA: No, I'm going to play for a certain team. So all of a sudden, I'm going to play for the team.\\n\\nQ: I've been told it's about a certain player, but I'm not going to play for it?\\n\\nA: No\"}]\n\n\nHere‚Äôs an example of using the first words of a famous haiku as a prompt, to see if the model can generate the next few lines (it doesn‚Äôt).\n\ngenerator(\"Old pond a frog jumps\", num_return_sequences=5)\n#expected completion - \"the sound of water\"\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\n[{'generated_text': 'Old pond a frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps up from under the water to attack a crocodile.\\n\\nA frog jumps'},\n {'generated_text': 'Old pond a frog jumps over a pond.\\n\\nA frog jumps over a pond. A large frog climbs up a large pond.\\n\\nA frog jumps over a pond. A small frog climbs over a small pond.\\n\\nA frog jumps over a pond. A large frog jumps over a pond.\\n\\nA frog jumps over a pond. A small frog jumps over a small pond.\\n\\nA frog jumps over a pond. A small frog jumps over a small pond.\\n\\nA frog jumps over a pond. A small frog jumps over a small pond.\\n\\nA frog jumps over a pond. A small frog jumps over a small pond.\\n\\nA frog jumps over a pond. A small frog jumps over a small pond.\\n\\nA frog jumps over a pond. A small frog jumps over a small pond.\\n\\nA frog jumps over a pond. A small frog jumps over a small pond.\\n\\nA frog jumps over a pond. A small frog jumps over a small pond.\\n\\nA frog jumps over a pond. A small frog jumps over a small pond.\\n\\nA frog jumps over a pond. A small frog jumps over a small pond.\\n\\nA frog jumps over a pond. A small frog jumps over a small pond.\\n'},\n {'generated_text': 'Old pond a frog jumps over.\\n\\nIn addition to being a common sight, however, it is also sometimes called a \"watermelon\" because of its color.\\n\\nWhat is a \"pest\" instead?\\n\\nThere are many different types of pest, and it is a common misconception that you need to know how to properly identify one.\\n\\nThere are different types of pest - the common, the exotic, and the exotic.\\n\\nThe exotic is a watermelon, and the common variety is a potted fruit.\\n\\nThe exotic is a watermelon with a little blood on the flesh.\\n\\nIn terms of flavor, the potted fruit is a bit more sweet, and the exotic is a bit more \"sugar.\"\\n\\nThe exotic is also known as a red-orange, and the common variety is a red-orange.\\n\\nOne of the most common types of pest is called a \"watermelon\" because it is yellowish.\\n\\nThe common variety is called \"potted fruit,\" but for some reason it is more common for the red-orange variety to be called a \"potted fruit.\"\\n\\nThe exotic variety is called a \"potted fruit,\" but for some reason, it is more common for'},\n {'generated_text': 'Old pond a frog jumps over.\\n\\n\"I\\'m not going to tell you a secret,\" she says. \"I\\'m not going to tell you a secret, but I do want to tell you something. But you\\'ve got to remember the name and what it means. It\\'s the name of this village. It\\'s the name of a village. And I\\'m going to tell you how it all started.\"\\n\\n\"What,\" says the girl.\\n\\n\"I was just talking to a local girl,\" says the frog. \"We met over a beer. She said she wanted to know the village name. Why didn\\'t you tell her?\"\\n\\n\"Because it was too hard for us to find out. It\\'s not even a village, isn\\'t it?\"\\n\\n\"No, it\\'s a village,\" says the frog. \"You see the name of this girl in the book, right? It\\'s here. It was here before the war. It\\'s the name of this village. It\\'s the name of a village. And I was so embarrassed that I couldn\\'t tell her. I had to put it away.\"\\n\\n\"I knew you wouldn\\'t know any better,\" answers the girl.'},\n {'generated_text': 'Old pond a frog jumps into the water. The frogs swim around the pond and go back to the pond. Eventually they get to the bottom of the pond. They make it to the bottom where they drown. The next morning the water is clear and the frogs start swimming again. Eventually they are able to get to the top of the pond and they all swim back down the hill.\\n\\n\\nThis is the only way to get to the top of the pond.\\n\\n\\nThe frog is back to the pond and when he comes back it is time to go back to the pond to get some water. The water is clear and the frog is right back up the hill.\\n\\n\\nThe frog is back to the pond and he is back to the pond.'}]\n\n\nMy 2020 method (prompting based on a haiku-related seed word) was essentially an ‚Äòaccidental haiku finder‚Äô combining generative text and procedural generation. (Spoiler alert - thanks to Claude, I‚Äôve now figured out that a few-shot approach would have generated better results without finetuning!)\n\n\nShow the 2020 code\n#export\n\n##General verse_gen - input is input, number of syllables required\n\ndef verse_gen(verse_input, syllable_length):\n    global verse_words\n    global verse_string\n    global verse_count\n    global verse_syllable_count\n    \n#Go to first whitespace, count syllables.  Continue until \"syllable_length\" syllables.  If over required amount syllables try with new input.\n#initialize counters\n\n    #left side location in string\n    y=0\n    \n    #right side location in string\n    x=1\n    \n    #counter for number of times to try this before getting new input\n    z=0\n    \n    #initial syllable count of zero\n    verse_syllable_count=0\n\n    #Split the input to make it a list of words\n    verse_words=verse_input.split(' ')\n\n#Set a counter - try this a number of times then move on\n    while z &lt; 40:\n    \n        if verse_syllable_count &lt; syllable_length:\n            print(\"Adding next word to the string\")\n        \n            #Put words from y to x in a string\n            verse_string=' '.join(verse_words[y:x])\n\n                \n            #If no special characters, Count the syllables\n            #Validate haiku-able phrases.  If not, reinitialize the string and keep going\n            \n            #Get rid of any phrase with numerals or special characters in it\n            \n            if re.match(\"^[a-zA-Z\\s-]*$\", verse_string):\n                verse_syllable_count = syllapy.count(verse_string)\n    \n                #increment x\n                x=x+1\n\n                #increment z\n                z=z+1\n\n                #print the string\n                print(verse_string)\n            \n            else:\n                print(verse_string, \"Invalid characters. Moving up in string.\")\n                #reinitialize verse_string\n                verse_string=\"\"\n                verse_syllable_count=0\n                y=y+1\n                \n            \n        if verse_syllable_count == syllable_length:\n            #Get rid of any trailing spaces\n            verse_string = verse_string.strip()\n            last_word=verse_string.split(\" \")[-1]\n            #Get rid of any phrase ending in an article or preposition words\n            \n            bad_word_list = 'as of the and if or at by our your my'\n            bad_word_set = set(bad_word_list.split())\n\n            if (last_word in bad_word_set):\n                \n                print(verse_string, \": String ends in article or other undesirable word.  Moving up in string\")\n                \n                #reinitialize verse_string\n                verse_string=\"\"\n                verse_syllable_count=0\n                y=y+1\n           \n            #If successful, print string and return    \n            else:\n                print(\"Haiku line found:\\n\", verse_string)\n                return verse_string\n    \n        if verse_syllable_count &gt; syllable_length:\n            #If string is too long, reinitialize the string and keep going\n\n            print(verse_string, \": String too long. Moving up in string.\")\n            \n            #reinitialize verse_string\n            verse_string=\"\"\n            verse_syllable_count=0\n            y=y+1\n            \n            #verse_gen(verse_input, syllable_length)\n\n    #Get a new string and start over if this string doesn't work\n    if z == 40:\n        print(\"Getting new input.\")\n        #text_generator(state_dict)   \n        verse_input = GPT2_output\n        verse_string=verse_gen(verse_input, syllable_length)\n        return verse_string\n\n#END OF VERSE ONE GEN    \n\n\ndef haiku_gen():\n    import random\n    global GPT2_seed_text\n    global haiku_seed\n    lines = open('sajiki.txt').read().splitlines()\n    GPT2_seed_text = random.choice(lines)\n    haiku_seed = GPT2_seed_text\n   \n    text_generator(state_dict)\n\n#Code to generate verse 1:\n    verse_string = \"\"\n    verse_input = GPT2_output\n    syllable_length = 5\n    verse_one_string=verse_gen(verse_input, syllable_length)\n    \n#Code to generate verse 2:\n    verse_string = \"\"\n    GPT2_seed_text = verse_one_string\n    text_generator(state_dict)\n    verse_input = GPT2_output\n    syllable_length = 7\n    verse_two_string=verse_gen(verse_input, syllable_length)\n\n#Code to generate verse 3:\n    verse_string = \"\"\n    GPT2_seed_text = verse_one_string\n    text_generator(state_dict)\n    verse_input = GPT2_output\n    syllable_length=5\n    verse_three_string=verse_gen(verse_input, syllable_length)\n\n#Print finished haiku\n    print(\"Here is the haiku seed:\")\n    print(haiku_seed)\n    print(\"Here is the haiku:\")\n\n#Print finished haiku\n \n    finished_haiku=''\n    finished_haiku='\\n'.join([verse_one_string,verse_two_string,verse_three_string])\n    print(finished_haiku)\n    \n    #Add finished haiku to a list and date\n    #Todo add date and time\n     #import datetime\n    from datetime import datetime\n\n    # get current date\n    now = datetime.now()\n    \n    # convert current date into timestamp\n    haiku_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n\n    f = open(\"haikulist.txt\", \"a\")\n    f.write(\"\\n\\nHaiku seed:\\n\"+haiku_seed+\"\\n\\nHaiku:\\n\"+finished_haiku+\"\\n\"+haiku_time)\n    f.close()\n    \n    #Place finished haiku in an input for GUI (clear it out first)\n    f = open(\"latesthaiku.txt\", \"w\")\n    f.write(finished_haiku)\n    f.close()\n\n\n    #Put verse2 in as GPT seedtext seed  ## This leads to too much convergence\n    \n  #  f.write(verse_two_string)\n  #  get sajiki from http://jti.lib.virginia.edu/japanese/haiku/saijiki/full.html  -&gt; sajiki.txt\n   \n    \n    import random\n    \n    from IPython.display import Audio\n\n    wave = np.sin(2*np.pi*400*np.arange(10000*2)/10000)\n    Audio(wave, rate=30000, autoplay=True)\n\n\n    \n##Run the module:\n\n#Initial arguments go here:\nfrom IPython.display import Audio\nargs_nsamples = 1\nargs_batch_size = -1\nargs_length = 1\nargs_unconditional = 0\nargs_temperature = 0.9\nargs_top_k = 40\nargs_quiet = 1\nverse_input = \"\"\nz = 0\n\nwhile z &lt; 100:\n   # lines = open('sajiki.txt').read().splitlines()\n   # GPT2_seed_text = random.choice(lines)\n   \n    haiku_gen()\n    \n    \n    #Beep after each iteration\n    wave = np.sin(2*np.pi*400*np.arange(10000*2)/10000)\n    Audio(wave, rate=30000, autoplay=True)\n    z+1\n    \n#Beep when all done\n\nwave = np.sin(2*np.pi*400*np.arange(10000*2)/10000)\nAudio(wave, rate=40000, autoplay=True)\n    \n\n\nHere‚Äôs an indicative result of a generated ‚Äúhaiku‚Äù:\n\nHaiku seed:\nk≈çri , ice\nHaiku:\nice water is\nextremely sensitive\nBut you might want to\n\nTo be clear, most of the results were terrible!\nHere are some of the more interesting generations:\nThere will be no\nshortage of good things going\nhave insurance\nShould we be worried\nare the implications\ntaking the first steps\nLactobacillus\nuse of a strain as a\nA novel species\nIt also generated some real oddballs and many nonsensical results -\n‚ÄúThe only\nnow will be my story. My\nnow is not a good\nwhich saw the season\npremiere of The Mummy\nand will likely\nAsking LLMs for help in 2025\nNow, could Claude in 2025 come up with a better solution?\n2025 prompt to Sonnet 4.5:\nI‚Äôd like you to use GPT-2 to create a haiku. I‚Äôm accessing GPT-2 by using a Jupyter notebook, using the following code. Please build off of this example to make a GPT-2 Haiku generator using Python script that I can run in a Jupyter notebook on my MacBook.\nfrom transformers import pipeline, set_seed\ngenerator = pipeline(‚Äòtext-generation‚Äô, model=‚Äògpt2‚Äô)\nset_seed(42)\ngenerator(‚ÄúHello, I‚Äôm a language model,‚Äù, max_length=30, num_return_sequences=5)\nHere‚Äôs Sonnet 4.5‚Äôs answer:\n\n\nCell 1\n# GPT-2 Haiku Generator - Jupyter Notebook Version\n# Copy each cell below into separate cells in your Jupyter notebook\n\n# ============================================\n# CELL 1: Install dependencies (if needed)\n# ============================================\n# Uncomment and run if you need to install transformers\n# !pip install transformers torch\n\n\n\n\nCell 2\n# ============================================\n# CELL 2: Import libraries and define functions\n# ============================================\nfrom transformers import pipeline, set_seed\nimport re\nimport random\n\n# Syllable counting using a simple heuristic\ndef count_syllables(word):\n    \"\"\"Count syllables in a word using vowel-counting heuristic.\"\"\"\n    word = word.lower().strip()\n    if len(word) == 0:\n        return 0\n    \n    word = re.sub(r'[^a-z]', '', word)\n    vowels = \"aeiouy\"\n    syllable_count = 0\n    previous_was_vowel = False\n    \n    for char in word:\n        is_vowel = char in vowels\n        if is_vowel and not previous_was_vowel:\n            syllable_count += 1\n        previous_was_vowel = is_vowel\n    \n    if word.endswith('e') and syllable_count &gt; 1:\n        syllable_count -= 1\n    \n    if syllable_count == 0:\n        syllable_count = 1\n    \n    return syllable_count\n\n\ndef count_line_syllables(line):\n    \"\"\"Count total syllables in a line of text.\"\"\"\n    words = re.findall(r'\\b[a-zA-Z]+\\b', line)\n    return sum(count_syllables(word) for word in words)\n\n\ndef generate_haiku_line(generator, prompt, target_syllables, max_attempts=50):\n    \"\"\"Generate a line with approximately the target number of syllables.\"\"\"\n    for attempt in range(max_attempts):\n        output = generator(\n            prompt,\n            max_length=20 + attempt,\n            num_return_sequences=1,\n            temperature=0.8 + (attempt * 0.02),\n            do_sample=True,\n            top_k=50,\n            top_p=0.95\n        )[0]['generated_text']\n        \n        generated = output[len(prompt):].strip()\n        lines = re.split(r'[.!?\\n]', generated)\n        if lines:\n            line = lines[0].strip()\n            syllables = count_line_syllables(line)\n            \n            if abs(syllables - target_syllables) &lt;= 1:\n                return line, syllables\n    \n    return line, syllables\n\n\ndef generate_haiku(seed=None, theme=\"nature\"):\n    \"\"\"Generate a haiku using GPT-2.\"\"\"\n    if seed is not None:\n        set_seed(seed)\n        random.seed(seed)\n    \n    generator = pipeline('text-generation', model='gpt2')\n    \n    theme_prompts = {\n        \"nature\": [\"The autumn leaves\", \"Morning dew on\", \"Cherry blossoms\", \n                   \"The mountain peak\", \"Ocean waves crash\"],\n        \"seasons\": [\"Winter snow falls\", \"Spring flowers bloom\", \"Summer heat waves\",\n                   \"Autumn winds blow\"],\n        \"zen\": [\"Silent meditation\", \"Peace surrounds the\", \"Quiet temple bell\",\n                \"Moonlight reflection\"],\n        \"ocean\": [\"The ocean tide\", \"Waves upon the\", \"Deep blue water\",\n                 \"Coastal sunset\"],\n        \"custom\": [theme]\n    }\n    \n    if theme in theme_prompts:\n        prompts = theme_prompts[theme]\n    else:\n        prompts = theme_prompts[\"custom\"]\n    \n    print(\"Generating haiku...\\n\")\n    \n    # Line 1: 5 syllables\n    prompt1 = random.choice(prompts)\n    line1, syl1 = generate_haiku_line(generator, prompt1, 5)\n    print(f\"Line 1 ({syl1} syllables): {line1}\")\n    \n    # Line 2: 7 syllables\n    line2, syl2 = generate_haiku_line(generator, line1 + \" \", 7)\n    print(f\"Line 2 ({syl2} syllables): {line2}\")\n    \n    # Line 3: 5 syllables\n    line3, syl3 = generate_haiku_line(generator, line2 + \" \", 5)\n    print(f\"Line 3 ({syl3} syllables): {line3}\")\n    \n    haiku = f\"{line1}\\n{line2}\\n{line3}\"\n    \n    print(\"\\n\" + \"=\"*50)\n    print(\"GENERATED HAIKU:\")\n    print(\"=\"*50)\n    print(haiku)\n    print(\"=\"*50)\n    print(f\"Syllable count: {syl1}-{syl2}-{syl3}\")\n    \n    return haiku\n\nprint(\"‚úÖ Functions loaded successfully!\")\n\n\n\n\n\n\nCell 3\n# ============================================\n# CELL 3: Generate a single haiku\n# ============================================\n\n# Generate one haiku with a specific seed\nhaiku = generate_haiku(seed=42, theme=\"nature\")\n\n\n==================================================\nGENERATED HAIKU:\n==================================================\nlook a bit too nice\nto use in any way\nin their own life\n==================================================\nSyllable count: 5-6-4\n\n\n\nCell 4\n# ============================================\n# CELL 4: Generate multiple haikus\n# ============================================\n\n# Generate 3 different haikus\nfor i in range(3):\n    print(f\"\\n{'#'*50}\")\n    print(f\"HAIKU #{i+1}\")\n    print(f\"{'#'*50}\\n\")\n    generate_haiku(seed=42+i, theme=\"nature\")\n\n\n==================================================\nGENERATED HAIKU:\n==================================================\nand the mountains\n ªOla ªo, but this would not happen\n ª‚Äù in the future\n==================================================\nSyllable count: 4-6-4\n\n\n\nCell 5\n# ============================================\n# CELL 5: Try different themes\n# ============================================\n\n# Try different themes\nthemes = [\"nature\", \"seasons\", \"zen\", \"ocean\"]\n\nfor theme in themes:\n    print(f\"\\nüå∏ Theme: {theme.upper()} üå∏\")\n    generate_haiku(seed=42, theme=theme)\n    print(\"\\n\")\n\n\n\n==================================================\nGENERATED HAIKU:\n==================================================\nwave and the sun\n- or a couple of times\na lot of times\n==================================================\nSyllable count: 4-6-5\n\n\n\nCell 6\n# ============================================\n# CELL 6: Custom theme\n# ============================================\n\n# Use your own custom starting phrase\ncustom_haiku = generate_haiku(seed=42, theme=\"The starry night\")\n\n\nThe results have some of the same issues (incoherence), but with fewer bad generations than the original method.\nAnd here‚Äôs what Opus 4.1 came up with. It relies more heavily on a set number of stock seed phrases. Opus proposed an ‚Äúadvanced‚Äù and ‚Äúsimplified‚Äù script; below is the ‚Äúadvanced‚Äù version. Unlike Sonnet, Opus did not actually configure the output code for a Jupyter notebook despite claiming to. I‚Äôve left the results below - they‚Äôre not great.\n\n\nOpus version code - Part 1\n\"\"\"\nGPT-2 Haiku Generator\nThis script uses GPT-2 to generate text and formats it into haikus (5-7-5 syllable structure)\n\"\"\"\n\nfrom transformers import pipeline, set_seed\nimport random\nimport re\nimport syllables  # You'll need to install: pip install syllables\n\nclass GPT2HaikuGenerator:\n    def __init__(self, model='gpt2'):\n        \"\"\"Initialize the GPT-2 generator\"\"\"\n        self.generator = pipeline('text-generation', model=model)\n        self.haiku_prompts = [\n            \"Cherry blossoms\",\n            \"Morning dewdrops\",\n            \"Autumn leaves fall\",\n            \"Winter silence\",\n            \"Summer breeze\",\n            \"Mountains standing\",\n            \"Ocean waves\",\n            \"Moonlight shining\",\n            \"Birds singing\",\n            \"Rain falling\"\n        ]\n    \n    def count_syllables(self, word):\n        \"\"\"Count syllables in a word using the syllables library\"\"\"\n        try:\n            return syllables.estimate(word)\n        except:\n            # Fallback: rough estimation if library fails\n            return max(1, len(re.findall(r'[aeiouAEIOU]', word)))\n    \n    def extract_words_with_syllables(self, text, target_syllables):\n        \"\"\"Extract words from text that sum to target syllables\"\"\"\n        words = re.findall(r'\\b\\w+\\b', text)\n        result = []\n        current_syllables = 0\n        \n        for word in words:\n            syllable_count = self.count_syllables(word)\n            if current_syllables + syllable_count &lt;= target_syllables:\n                result.append(word)\n                current_syllables += syllable_count\n                if current_syllables == target_syllables:\n                    break\n        \n        return ' '.join(result), current_syllables\n    \n    def generate_haiku_from_text(self, text):\n        \"\"\"Try to format generated text into haiku structure\"\"\"\n        # Clean the text\n        text = re.sub(r'[^\\w\\s]', '', text)\n        words = text.split()\n        \n        if len(words) &lt; 10:\n            return None\n        \n        # Try to build haiku lines\n        line1, syll1 = self.extract_words_with_syllables(' '.join(words), 5)\n        remaining_words = ' '.join(words[len(line1.split()):])\n        \n        line2, syll2 = self.extract_words_with_syllables(remaining_words, 7)\n        remaining_words = ' '.join(words[len(line1.split()) + len(line2.split()):])\n        \n        line3, syll3 = self.extract_words_with_syllables(remaining_words, 5)\n        \n        # Check if we got close enough to proper syllable counts\n        if (4 &lt;= syll1 &lt;= 6) and (6 &lt;= syll2 &lt;= 8) and (4 &lt;= syll3 &lt;= 6):\n            return f\"{line1}\\n{line2}\\n{line3}\"\n        \n        return None\n    \n    def generate_haiku(self, prompt=None, temperature=0.8, max_attempts=10):\n        \"\"\"Generate a haiku using GPT-2\"\"\"\n        if prompt is None:\n            prompt = random.choice(self.haiku_prompts)\n        \n        set_seed(random.randint(1, 1000))\n        \n        for attempt in range(max_attempts):\n            # Generate text with GPT-2\n            generated = self.generator(\n                prompt,\n                max_length=50,\n                num_return_sequences=3,\n                temperature=temperature,\n                pad_token_id=50256  # GPT-2's EOS token\n            )\n            \n            # Try to format each generated text as haiku\n            for result in generated:\n                text = result['generated_text']\n                # Remove the prompt from the beginning\n                text = text[len(prompt):].strip()\n                \n                haiku = self.generate_haiku_from_text(text)\n                if haiku:\n                    return f\"Prompt: {prompt}\\n\\n{haiku}\"\n        \n        # Fallback: return best attempt even if syllables aren't perfect\n        return self.create_simple_haiku(prompt)\n    \n    def create_simple_haiku(self, prompt):\n        \"\"\"Create a simple haiku by taking first words from generation\"\"\"\n        generated = self.generator(prompt, max_length=30, temperature=0.9)\n        text = generated[0]['generated_text'][len(prompt):].strip()\n        words = re.findall(r'\\b\\w+\\b', text)\n        \n        if len(words) &gt;= 7:\n            return f\"Prompt: {prompt}\\n\\n{' '.join(words[:2])}\\n{' '.join(words[2:5])}\\n{' '.join(words[5:7])}\"\n        else:\n            return f\"Prompt: {prompt}\\n\\n{prompt}\\n{' '.join(words[:3]) if len(words) &gt;= 3 else 'whispers softly here'}\\n{'in the quiet air' if len(words) &lt; 5 else ' '.join(words[3:5])}\"\n\n# Example usage in Jupyter notebook:\n#if __name__ == \"__main__\":\n    # Initialize the haiku generator\n ###  Note - I had to comment out the above since Opus did not actually configure this properly in cells for a Jupyter notebook   \n\n\n\n\nOpus version code - Part 2\nhaiku_gen = GPT2HaikuGenerator()\n    \n# Generate haikus with different prompts\nprint(\"=\" * 50)\nprint(\"GPT-2 HAIKU GENERATOR\")\nprint(\"=\" * 50)\n    \n# Generate 5 haikus\nfor i in range(5):\n    print(f\"\\nHaiku #{i+1}:\")\n    print(\"-\" * 20)\n    haiku = haiku_gen.generate_haiku()\n    print(haiku)\n    print()\n    \n# Generate haiku with custom prompt\nprint(\"\\nCustom Prompt Haiku:\")\nprint(\"-\" * 20)\ncustom_haiku = haiku_gen.generate_haiku(prompt=\"The old computer\")\nprint(custom_haiku)\n\n\nDevice set to use mps:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nBoth `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n\n\n==================================================\nGPT-2 HAIKU GENERATOR\n==================================================\n\nHaiku #1:\n--------------------\n\n\nBoth `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n\n\nPrompt: Summer breeze\n\nblowing through the sky\nmade his eyes look up But in\nthe background the wind\n\n\nHaiku #2:\n--------------------\n\n\nBoth `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n\n\nPrompt: Morning dewdrops\n\nc9jpg We have some in\nissues in the with the going\npipeline going\n\n\nHaiku #3:\n--------------------\n\n\nBoth `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n\n\nPrompt: Ocean waves\n\nFrozen rock is an\nunusual thing to see Its\nalmost like a ghost\n\n\nHaiku #4:\n--------------------\n\n\nBoth `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n\n\nPrompt: Morning dewdrops\n\nto show his power\nI see youre a little\nbit nervous I guess\n\n\nHaiku #5:\n--------------------\n\n\nBoth `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n\n\nPrompt: Rain falling\n\nand hitting the ground\nBut if you look at the you\nyou cant help but of\n\n\nCustom Prompt Haiku:\n--------------------\nPrompt: The old computer\n\nfrom the 90s Im sure\nThe new one can handle\neven more work The\n\n\nTrying Claude Haiku\nAnd of course, we must also try Claude Haiku! Here‚Äôs what Haiku 4.5 comes up with. It also uses a limited set of indicative prompts ([‚ÄúThe forest‚Äù, ‚ÄúMorning light‚Äù, ‚ÄúWater flows‚Äù, ‚ÄúSummer breeze‚Äù]) and the results are similar to the other Claude models - not great, and occasionally problematic.\n\n\nClaude Haiku 4.5 code\nfrom transformers import pipeline, set_seed\nimport re\n\n# Initialize the GPT-2 text generation pipeline\ngenerator = pipeline('text-generation', model='gpt2')\nset_seed(42)\n\ndef generate_haiku_text(prompt=\"The\", max_length=50, num_attempts=10):\n    \"\"\"\n    Generate text using GPT-2 and attempt to format it as a haiku.\n    \n    Args:\n        prompt (str): Starting text for generation\n        max_length (int): Maximum length of generated text\n        num_attempts (int): Number of generation attempts to find a good haiku\n    \n    Returns:\n        str: Formatted haiku (or None if no valid haiku found)\n    \"\"\"\n    \n    for attempt in range(num_attempts):\n        # Generate text\n        generated_text = generator(prompt, max_length=max_length, num_return_sequences=1)\n        text = generated_text[0]['generated_text']\n        \n        # Clean up text: remove special characters and extra whitespace\n        text = re.sub(r'[^\\w\\s]', '', text)\n        text = re.sub(r'\\s+', ' ', text).strip()\n        \n        # Split into words\n        words = text.split()\n        \n        # Try to create a haiku (5-7-5 syllable structure)\n        haiku = create_haiku_from_words(words)\n        \n        if haiku:\n            return haiku\n    \n    return \"Could not generate a valid haiku. Try again!\"\n\ndef count_syllables(word):\n    \"\"\"\n    Estimate syllable count using a simple heuristic.\n    This is not perfect but works reasonably well for English.\n    \"\"\"\n    word = word.lower()\n    syllable_count = 0\n    vowels = \"aeiouy\"\n    previous_was_vowel = False\n    \n    for char in word:\n        is_vowel = char in vowels\n        if is_vowel and not previous_was_vowel:\n            syllable_count += 1\n        previous_was_vowel = is_vowel\n    \n    # Adjust for silent 'e'\n    if word.endswith('e'):\n        syllable_count -= 1\n    \n    # Words have at least 1 syllable\n    if syllable_count == 0:\n        syllable_count = 1\n    \n    return syllable_count\n\ndef create_haiku_from_words(words):\n    \"\"\"\n    Create a haiku from a list of words using 5-7-5 syllable structure.\n    \n    Returns:\n        str: Formatted haiku, or None if not enough syllables\n    \"\"\"\n    lines = [[], [], []]\n    syllable_counts = [0, 0, 0]\n    target_syllables = [5, 7, 5]\n    word_index = 0\n    \n    while word_index &lt; len(words) and sum(syllable_counts) &lt; 17:\n        word = words[word_index]\n        syllables = count_syllables(word)\n        \n        # Find which line to add to (cycle through lines)\n        for line_num in range(3):\n            if syllable_counts[line_num] + syllables &lt;= target_syllables[line_num]:\n                lines[line_num].append(word)\n                syllable_counts[line_num] += syllables\n                word_index += 1\n                break\n        else:\n            # If word doesn't fit anywhere, move to next word\n            word_index += 1\n    \n    # Check if we have a valid haiku (5-7-5)\n    if syllable_counts == target_syllables and all(lines):\n        haiku = '\\n'.join([' '.join(line) for line in lines])\n        return haiku\n    \n    return None\n\n# Generate and display haikus\nprint(\"GPT-2 Haiku Generator\")\nprint(\"=\" * 40)\n\n# Generate multiple haikus with different prompts\nprompts = [\"The forest\", \"Morning light\", \"Water flows\", \"Summer breeze\"]\n\nfor i, prompt in enumerate(prompts, 1):\n    print(f\"\\nHaiku {i} (prompt: '{prompt}'):\")\n    print(\"-\" * 40)\n    haiku = generate_haiku_text(prompt, max_length=50, num_attempts=10)\n    print(haiku)\n\nprint(\"\\n\" + \"=\" * 40)\nprint(\"Generation complete!\")\n\n\nDevice set to use mps:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nBoth `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n\n\nGPT-2 Haiku Generator\n========================================\n\nHaiku 1 (prompt: 'The forest'):\n----------------------------------------\n\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nBoth `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n\n\nThe forest is with\nmostly filled the leaves\nof a dead tree and\n\nHaiku 2 (prompt: 'Morning light'):\n----------------------------------------\n\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nBoth `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n\n\nMorning light on the\nmorning of the 911 attacks\nOn this day were that\n\nHaiku 3 (prompt: 'Water flows'):\n----------------------------------------\n\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nBoth `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n\n\nWater flows I have\na feeling that when they give\nme something they\n\nHaiku 4 (prompt: 'Summer breeze'):\n----------------------------------------\nSummer breeze Its a\nbeautiful day he says And\nIm sure well see you\n\n========================================\nGeneration complete!\n\n\nTrying OpenAI \nThis is ChatGPT 5‚Äôs response without turning on ‚Äúthinking mode‚Äù - the prompts it suggests don‚Äôt seem ideal for GPT-2.\n\n\nChatGPT 5 code\n# Import required libraries\nfrom transformers import pipeline, set_seed\nimport random\nimport textwrap\n\n# Initialize GPT-2 text generation pipeline\ngenerator = pipeline('text-generation', model='gpt2')\nset_seed(42)\n\n# Define a list of possible prompts (you can edit or expand this list)\nprompts = [\n    \"Write a haiku about the changing seasons:\",\n    \"Compose a haiku about solitude:\",\n    \"A haiku describing dawn in the city:\",\n    \"A haiku about a cat in the rain:\",\n    \"Write a haiku about stars and silence:\"\n]\n\n# Helper function to generate a haiku\ndef generate_haiku(prompt=None, temperature=0.9, max_length=40):\n    if prompt is None:\n        prompt = random.choice(prompts)\n    print(f\"ü™∂ Prompt: {prompt}\\n\")\n    \n    # Generate text\n    output = generator(\n        prompt,\n        max_length=max_length,\n        num_return_sequences=1,\n        temperature=temperature,\n        pad_token_id=50256\n    )[0]['generated_text']\n    \n    # Clean and format\n    text = output.replace(prompt, \"\").strip()\n    text = text.split(\".\")[0]  # trim at first full stop to keep short\n    lines = textwrap.wrap(text, width=25)[:3]  # 3 lines (approx haiku)\n    \n    # Format result as haiku\n    haiku = \"\\n\".join(lines)\n    print(\"üå∏ Generated Haiku:\\n\")\n    print(haiku)\n    return haiku\n\n    \n\n\nDevice set to use mps:0\n\n\n\n# ‚ú® Generate your first haiku!\ngenerate_haiku()\n\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nBoth `max_new_tokens` (=256) and `max_length`(=40) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n\n\nü™∂ Prompt: Write a haiku about the changing seasons:\n\nüå∏ Generated Haiku:\n\nThe last of the season\nwas called \"Rome\"\n\n\n'The last of the season\\nwas called \"Rome\"'\n\n\nUsing ChatGPT 5 in Thinking Mode\nThe code that thinking mode generated is more complex, and the model even suggested a number of notes and tips to make the haiku more stylistically nuanced. But the code didn‚Äôt work.\n\n\nChatGPT 5 code - Thinking mode\n# If needed, install deps (uncomment the next line and run once)\n# !pip install --quiet transformers torch regex numpy nltk pronouncing\n\nfrom transformers import pipeline, set_seed\nimport re, random, itertools\nimport numpy as np\n\n# --- Syllable counting helpers (CMUdict + heuristic fallback) ---\ntry:\n    import nltk\n    from nltk.corpus import cmudict\n    try:\n        _ = cmudict.dict()\n    except LookupError:\n        nltk.download(\"cmudict\")\n    CMU = cmudict.dict()\nexcept Exception:\n    CMU = {}\n\n_vowel_re = re.compile(r\"[aeiouy]+\", re.I)\n\ndef _cmu_syllables(word: str):\n    \"\"\"Return min syllables from CMU if available, else None.\"\"\"\n    w = word.lower()\n    if w in CMU:\n        # Count vowel phonemes ending with a digit (stress marks)\n        return min(sum(ch[-1].isdigit() for ch in pron) for pron in CMU[w])\n    return None\n\ndef _heuristic_syllables(word: str):\n    \"\"\"Lightweight heuristic when CMUdict lacks the word.\"\"\"\n    w = word.lower()\n    w = re.sub(r\"[^a-z']\", \"\", w)\n    if not w:\n        return 0\n    # Basic vowel group counting\n    syl = len(_vowel_re.findall(w))\n    # Silent 'e' adjustment\n    if w.endswith(\"e\") and syl &gt; 1 and not re.search(r\"[aeiouy]e$\", w):\n        syl -= 1\n    # Some common endings\n    if w.endswith((\"le\",\"les\")) and not re.search(r\"[aeiouy]le?s?$\", w[:-2]):\n        syl += 1\n    return max(1, syl)\n\ndef count_syllables(text: str) -&gt; int:\n    total = 0\n    for raw in re.findall(r\"[A-Za-z']+\", text):\n        cmu = _cmu_syllables(raw)\n        total += cmu if cmu is not None else _heuristic_syllables(raw)\n    return total\n\n# --- Haiku validation ---\ndef is_haiku(lines):\n    \"\"\"Check 5-7-5 syllable pattern and basic cleanliness.\"\"\"\n    if len(lines) != 3:\n        return False\n    targets = [5, 7, 5]\n    for line, tgt in zip(lines, targets):\n        s = count_syllables(line)\n        if s != tgt:\n            return False\n        # Avoid lines that are just punctuation or empties\n        if not re.search(r\"[A-Za-z]\", line):\n            return False\n    return True\n\n# --- Build the GPT-2 generator (your base example, expanded) ---\nset_seed(42)\ngenerator = pipeline(\"text-generation\", model=\"gpt2\")  # can swap to \"gpt2-medium\" if you like\n\n# --- Prompt & sampling strategy ---\nSYSTEM_PROMPT = (\n    \"Write three short poetic lines separated by newlines.\\n\"\n    \"Avoid rhyming schemes. Natural imagery is welcome.\\n\"\n    \"Keep each line concise and evocative.\\n\\n\"\n    \"Lines:\\n\"\n)\n\ndef sample_lines(n_candidates=100, temperature=0.9, top_p=0.95, max_new_tokens=40):\n    \"\"\"\n    Ask GPT-2 for short three-line snippets and yield candidate line triplets.\n    We generate multiple short samples per call to find valid 5-7-5s.\n    \"\"\"\n    out = generator(\n        SYSTEM_PROMPT,\n        do_sample=True,\n        temperature=temperature,\n        top_p=top_p,\n        max_new_tokens=max_new_tokens,\n        num_return_sequences=n_candidates,\n        pad_token_id=50256,   # GPT-2's EOS\n        eos_token_id=50256,\n        repetition_penalty=1.05,\n    )\n    for obj in out:\n        # Take only the portion after \"Lines:\" to the first blank line or EOS\n        text = obj[\"generated_text\"]\n        after = text.split(\"Lines:\", 1)[-1].strip()\n        # Keep just the first 3 non-empty lines\n        lines = [ln.strip(\" -*\\t\") for ln in after.splitlines() if ln.strip()]\n        if len(lines) &gt;= 3:\n            yield lines[:3]\n\ndef generate_haiku(\n    attempts=8,\n    batch_size=80,\n    temperature=0.9,\n    top_p=0.95,\n    dedupe=True,\n):\n    \"\"\"\n    Try several batches until a valid 5-7-5 haiku is found.\n    Returns a list of candidate haiku (each is a list of 3 lines).\n    \"\"\"\n    seen = set()\n    candidates = []\n    for _ in range(attempts):\n        for lines in sample_lines(\n            n_candidates=batch_size, temperature=temperature, top_p=top_p\n        ):\n            # Clean trailing punctuation-only tokens\n            lines = [re.sub(r\"\\s+\", \" \", ln).strip() for ln in lines]\n            if dedupe:\n                key = \" | \".join(lines).lower()\n                if key in seen:\n                    continue\n                seen.add(key)\n            if is_haiku(lines):\n                candidates.append(lines)\n        if candidates:\n            break\n        # Slightly anneal temperature if nothing matched yet\n        temperature = max(0.7, temperature - 0.05)\n        top_p = min(0.98, top_p + 0.01)\n    return candidates\n\n# --- Run it: generate one or more haiku ---\nhaikus = generate_haiku(attempts=10, batch_size=100)   \nif not haikus:\n    print(\"No strict 5-7-5 found this round. Try re-running the cell or raise batch_size.\")\nelse:\n    for i, h in enumerate(haikus[:5], 1):\n        print(f\"\\nHaiku {i}:\\n\" + \"\\n\".join(h))\n\n\nDevice set to use mps:0\n\n\nNo strict 5-7-5 found this round. Try re-running the cell or raise batch_size.\n\n\nFirst an error message resulted- ‚ÄúNo strict 5-7-5 found this round. Try re-running the cell or raise batch_size.‚Äù The next attempt resulted in an out of memory error! I don‚Äôt think this approach would have been effective on the Jetson Nano.\nAsking Claude to prompt engineer\nIn this example, I explicitly prompted Sonnet 4.5 to ask for code to generate novel haikus while keeping the limitations of GPT-2 in mind. Sonnet 4.5‚Äôs response was few-shot prompting. The results were better than the previous strategies. Below is Claude‚Äôs explanation, the code, and the results.\n\nI‚Äôll create a GPT-2 haiku generator with a novel prompting strategy that works around GPT-2‚Äôs limitations. The key insight is that GPT-2 works better with concrete examples and structured patterns, so I‚Äôll use few-shot prompting with carefully crafted haiku examples.\n\n\n\nSonnet 4.5 code - revised prompt\n# GPT-2 Haiku Generator for Jupyter Notebook\n# Run each cell in order\n\n# Cell 1: Import and Setup\nfrom transformers import pipeline, set_seed\nimport re\nimport random\n\n# Initialize GPT-2\nprint(\"Loading GPT-2 model...\")\ngenerator = pipeline('text-generation', model='gpt2')\nprint(\"Model loaded successfully!\")\n\n# Cell 2: Helper Functions\ndef count_syllables(word):\n    \"\"\"Approximate syllable counter\"\"\"\n    word = word.lower().strip()\n    if len(word) &lt;= 3:\n        return 1\n    \n    vowels = \"aeiouy\"\n    syllable_count = 0\n    previous_was_vowel = False\n    \n    for char in word:\n        is_vowel = char in vowels\n        if is_vowel and not previous_was_vowel:\n            syllable_count += 1\n        previous_was_vowel = is_vowel\n    \n    if word.endswith('e'):\n        syllable_count -= 1\n    if word.endswith('le') and len(word) &gt; 2 and word[-3] not in vowels:\n        syllable_count += 1\n    \n    return max(1, syllable_count)\n\ndef count_line_syllables(line):\n    \"\"\"Count syllables in a line\"\"\"\n    words = re.findall(r'\\b[a-z]+\\b', line.lower())\n    return sum(count_syllables(word) for word in words)\n\n# Cell 3: Prompting Strategy\ndef create_haiku_prompt(theme=None):\n    \"\"\"\n    Novel Prompting Strategy:\n    - Use few-shot learning with 2 example haikus\n    - Provide clear structure with \"Haiku:\" labels\n    - Leave incomplete to trigger completion\n    \"\"\"\n    examples = [\n        (\"spring\", \"Cherry blossoms fall\\nPetals dance on gentle wind\\nSpring whispers softly\"),\n        (\"ocean\", \"Waves crash on the shore\\nSalty spray touches my face\\nOcean breathes deeply\"),\n        (\"winter\", \"Snow blankets the ground\\nSilence wraps the frozen world\\nWinter dreams in white\"),\n        (\"night\", \"Moon rises slowly\\nStars shimmer in velvet sky\\nNight embraces earth\"),\n        (\"autumn\", \"Leaves turn gold and red\\nCrisp air brings change to the trees\\nAutumn paints the world\"),\n    ]\n    \n    # Select relevant examples\n    if theme and any(theme.lower() in ex[0] for ex in examples):\n        selected = [ex for ex in examples if theme.lower() in ex[0]][0]\n        other_examples = [ex for ex in examples if ex != selected]\n        prompt_examples = [selected] + random.sample(other_examples, 1)\n    else:\n        prompt_examples = random.sample(examples, 2)\n    \n    prompt = \"Here are beautiful haikus:\\n\\n\"\n    for theme_name, haiku in prompt_examples:\n        prompt += f\"Haiku:\\n{haiku}\\n\\n\"\n    \n    if theme:\n        prompt += f\"Haiku about {theme}:\\n\"\n    else:\n        prompt += \"Haiku:\\n\"\n    \n    return prompt\n\n# Cell 4: Extraction and Validation\ndef extract_haiku_from_output(text, max_lines=10):\n    \"\"\"Extract potential haiku lines\"\"\"\n    lines = text.split('\\n')\n    haiku_candidates = []\n    \n    for line in lines[:max_lines]:\n        line = line.strip()\n        if not line or len(line) &gt; 60 or line.startswith('Haiku'):\n            continue\n        haiku_candidates.append(line)\n    \n    return haiku_candidates\n\ndef find_best_haiku(candidates):\n    \"\"\"Find best 5-7-5 pattern\"\"\"\n    if len(candidates) &lt; 3:\n        return None\n    \n    for i in range(len(candidates) - 2):\n        line1, line2, line3 = candidates[i:i+3]\n        syl1 = count_line_syllables(line1)\n        syl2 = count_line_syllables(line2)\n        syl3 = count_line_syllables(line3)\n        \n        # Accept if close to 5-7-5 (within 1 syllable)\n        if (4 &lt;= syl1 &lt;= 6 and 6 &lt;= syl2 &lt;= 8 and 4 &lt;= syl3 &lt;= 6):\n            return (line1, line2, line3, syl1, syl2, syl3)\n    \n    return None\n\n# Cell 5: Main Generator Function\ndef generate_haiku(theme=None, seed=None, num_attempts=5):\n    \"\"\"Generate a haiku with multiple attempts\"\"\"\n    if seed is not None:\n        set_seed(seed)\n    \n    best_result = None\n    \n    for attempt in range(num_attempts):\n        prompt = create_haiku_prompt(theme)\n        temperature = 0.7 + (attempt * 0.1)\n        \n        output = generator(\n            prompt,\n            max_new_tokens=50,  # Generate up to 50 new tokens after the prompt;\n            num_return_sequences=1,\n            temperature=temperature,\n            top_p=0.9,\n            do_sample=True,\n            pad_token_id=50256\n        )[0]['generated_text']\n        \n        generated = output[len(prompt):]\n        candidates = extract_haiku_from_output(generated)\n        result = find_best_haiku(candidates)\n        \n        if result:\n            line1, line2, line3, syl1, syl2, syl3 = result\n            score = abs(5 - syl1) + abs(7 - syl2) + abs(5 - syl3)\n            \n            if best_result is None or score &lt; best_result['score']:\n                best_result = {\n                    'haiku': f\"{line1}\\n{line2}\\n{line3}\",\n                    'syllables': f\"{syl1}-{syl2}-{syl3}\",\n                    'score': score,\n                    'attempt': attempt + 1\n                }\n            \n            if score == 0:\n                break\n    \n    return best_result\n\n# Cell 6: Generate a Single Haiku\n# Try different themes: \"mountain\", \"rain\", \"fire\", \"sunset\", \"river\", etc.\nresult = generate_haiku(theme=\"mountain\", seed=42, num_attempts=8)\n\nif result:\n    print(f\"Generated Haiku (Pattern: {result['syllables']}):\\n\")\n    print(result['haiku'])\n    print(f\"\\n(Found on attempt {result['attempt']})\")\nelse:\n    print(\"Couldn't generate a valid haiku. Try running the cell again!\")\n\n# Cell 7: Generate Multiple Haikus (Optional)\ndef generate_multiple_haikus(theme=None, count=3):\n    \"\"\"Generate multiple haikus\"\"\"\n    print(f\"Generating {count} haikus\" + (f\" about '{theme}'\" if theme else \"\") + \"...\\n\")\n    \n    for i in range(count):\n        seed = random.randint(1, 10000)\n        result = generate_haiku(theme=theme, seed=seed, num_attempts=8)\n        \n        if result:\n            print(f\"Haiku #{i+1} ({result['syllables']}):\")\n            print(result['haiku'])\n            print()\n\n# Run this to generate multiple haikus\ngenerate_multiple_haikus(theme=\"ocean\", count=3)\n\n\nLoading GPT-2 model...\n\n\nDevice set to use mps:0\n\n\nModel loaded successfully!\nGenerated Haiku (Pattern: 4-6-4):\n\nSnow melts my eyes\nSnow falls on the mountain\nSnow melts my ears\n\n(Found on attempt 2)\nGenerating 3 haikus about 'ocean'...\n\nHaiku #1 (4-6-6):\nA warm ocean\nSnow is my only hope\nHiku about ocean:\n\nHaiku #2 (6-7-6):\nRaindrops fly from the sky\nA gentle breeze is blowing\nHiku about ocean:\n\nHaiku #3 (5-6-5):\nTrees stand on the shore\nHair rises on a tree\nHair grows on a tree\n\n\n\nAs a comparison, here‚Äôs what happens when I asked Sonnet 4.5 to ‚ÄúWrite me a few haiku poems that nobody‚Äôs ever heard before‚Äù:\n\nHere are some original haiku I‚Äôve written for you:\nMorning Commute Coffee steam spirals‚Äî the train window fogs with breath of a hundred dreams\nKitchen Counter Garlic skin whispers as it falls to the tile floor‚Äî small paper crescents\nLate Night Coding Cursor blinks, waiting my thoughts already scattered to tomorrow‚Äôs bugs\nAutumn Discovery Between fence pickets a spider wraps October in silver patience\nLaundromat Socks tumble, dancing with strangers‚Äô forgotten shirts‚Äî brief intimacy\nI hope you enjoy these! Each one tries to capture a small, specific moment that feels both ordinary and quietly meaningful.\n\nAnd these are haikus from Claude Haiku 4.5:\n\nHere are some original haikus for you:\nRust blooms on the gate\nA garden‚Äôs slow forgetting‚Äî\nTime paints what we leave.\nCoffee cools untouched,\nwhile my thoughts drift elsewhere now,\nsteam vanishes fast.\nThe dog knows my face\nbut not why I look away‚Äî\nboth of us are lost.\nGravel crunches soft\nbeneath the weight of going,\nnowhere calls me back.\n\nNext Steps\nCan an LLM write a better haiku than this? I‚Äôm not sure I‚Äôd be capable of judging that. It seems ironic that a massive language model would be necessary to generate such a small poem. Small, specialized LLMs can save energy and run without an internet connection, so I think it could be beneficial to keep exploring ways they might be used to generate creative output.\n\n(Prompt to Haiku 4.5):\nWrite me a haiku about the singularity\n\n\nHere‚Äôs one for you:\nCode dreams of itself,\neach line birthing the next thought‚Äî\nwho was the first mind?\n\n\nLicense: This work is licensed under CC BY-ND 4.0 (Attribution-NoDerivatives) AI training and data mining prohibited."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thoughts on AI",
    "section": "",
    "text": "Writing Haiku with GPT-2 Without Finetuning\n\n\n\nLLM\n\ncode\n\nJetson Nano\n\nPyTorch\n\n\n\nRevisiting the first time I tried to get an LLM to write poetry\n\n\n\n\n\nNov 1, 2025\n\n\nMatthew Pagett\n\n\n\n\n\nNo matching items"
  }
]